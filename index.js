// index.js â€” ä¼šè©±ã§ãã‚‹å ã„LINE Botï¼ˆå±¥æ­´ãƒ¡ãƒ¢ãƒª + GPTï¼‰

import express from "express";
import fetch from "node-fetch";
import { Client, middleware } from "@line/bot-sdk";

const config = {
  channelAccessToken: process.env.LINE_ACCESS_TOKEN,
  channelSecret: process.env.LINE_CHANNEL_SECRET,
};

if (!config.channelAccessToken || !config.channelSecret) {
  console.error("LINEç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚");
}

const app = express();
const client = new Client(config);

// ---- ä¼šè©±ãƒ¡ãƒ¢ãƒªï¼ˆç°¡æ˜“/ãƒ—ãƒ­ã‚»ã‚¹å†…ï¼‰ ----
const sessions = new Map(); // userId -> [{role, content}]
const MAX_TURNS = 12;

// ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
app.get("/health", (_, res) => res.status(200).send("healthy"));
app.get("/", (_, res) => res.status(200).send("OK"));
app.get("/env", (_, res) => {
  res.json({
    MODEL: process.env.MODEL || "gpt-4o-mini",
    OPENAI: !!process.env.OPENAI_API_KEY,
  });
});

// Webhook å—ä¿¡
app.post("/webhook", middleware(config), async (req, res) => {
  try {
    const events = req.body?.events ?? [];
    await Promise.all(events.map(handleEvent));
    res.sendStatus(200);
  } catch (e) {
    console.error("webhook error:", e);
    res.sendStatus(500);
  }
});

async function handleEvent(event) {
  if (event.type !== "message" || event.message.type !== "text") return;

  const userId = event.source.userId;
  const text = (event.message.text || "").trim();
  console.log("LINE msg:", userId, text);

  // ---- ã‚³ãƒãƒ³ãƒ‰ ----
  if (["/reset","ãƒªã‚»ãƒƒãƒˆ","reset"].includes(text)) {
    sessions.delete(userId);
    return client.replyMessage(event.replyToken, { type: "text", text: "å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚ä½•ã‚’å ã„ã¾ã™ã‹ï¼Ÿ" });
  }
  if (["/menu","ãƒ¡ãƒ‹ãƒ¥ãƒ¼","help","ï¼Ÿ","?"].includes(text)) {
    return client.replyMessage(event.replyToken, { type: "text", text:
      "ğŸ”® å ã„ãƒ¡ãƒ‹ãƒ¥ãƒ¼\nãƒ»ç·åˆé‘‘å®š\nãƒ»æ‹æ„›/å¾©ç¸/ç‰‡æƒ³ã„\nãƒ»ä»•äº‹/è»¢è·\nãƒ»é‡‘é‹\nãƒ»å¥åº·/ç”Ÿæ´»ãƒªã‚ºãƒ \n\nâ€»ã€Œãƒªã‚»ãƒƒãƒˆã€ã§å±¥æ­´æ¶ˆå»" });
  }

  // ---- å±¥æ­´æ›´æ–° ----
  const hist = sessions.get(userId) || [];
  hist.push({ role: "user", content: text });
  while (hist.length > MAX_TURNS) hist.shift();

  // ---- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ----
  const prompt = buildPrompt(hist);

  // ---- ç”Ÿæˆï¼ˆOpenAIï¼‰ ----
  const reply = await generateWithOpenAI(prompt, hist) || fallbackReply();

  // å±¥æ­´ã¸è¿½åŠ 
  hist.push({ role: "assistant", content: reply });
  sessions.set(userId, hist);

  // è¿”ä¿¡
  return client.replyMessage(event.replyToken, { type: "text", text: reply.slice(0, 4900) });
}

function buildPrompt(history) {
  const recent = history.slice(-6)
    .map(m => `${m.role === "user" ? "ãƒ¦ãƒ¼ã‚¶ãƒ¼" : "å ã„å¸«"}ï¼š${m.content}`)
    .join("\n");

  return `ã‚ãªãŸã¯æ—¥æœ¬èªã§é‘‘å®šã™ã‚‹ãƒ—ãƒ­å ã„å¸«ã€ã‚Šã‚…ã†ã›ã„ã€ã€‚
çµè«–â†’ç†ç”±â†’ã‚¢ã‚¯ã‚·ãƒ§ãƒ³â†’æ³¨æ„ç‚¹â†’ã²ã¨ã“ã¨åŠ±ã¾ã— ã®é †ã§300ã€œ500å­—ã€‚
æ–­å®šã—ã™ããšã‚„ã•ã—ã„æ•¬èªã§ã€å®Ÿè¡Œå¯èƒ½ãªææ¡ˆã‚’å¿…ãšå…¥ã‚Œã‚‹ã€‚
åŒ»ç™‚ãƒ»æ³•å¾‹ãƒ»æŠ•è³‡ã®ç¢ºç´„ã¯ç¦æ­¢ã€‚ç›¸æ‰‹ã‚’ä¸å®‰ã«ã•ã›ã‚‹è¡¨ç¾ã¯é¿ã‘ã‚‹ã€‚

ã€ç›´è¿‘ä¼šè©±è¦ç´„ã€‘
${recent || "ï¼ˆåˆå›ï¼‰"}

ã€é‘‘å®šã€‘`;
}

async function generateWithOpenAI(prompt, history) {
  const apiKey = process.env.OPENAI_API_KEY;
  const model = process.env.MODEL || "gpt-4o-mini";
  if (!apiKey) {
    console.warn("OPENAI_API_KEY ãŒæœªè¨­å®š");
    return null;
  }
  try {
    const messages = [
      { role: "system", content:
        "ã‚ãªãŸã¯æ¸©ã‹ãèª å®Ÿãªå ã„å¸«ã€ã‚Šã‚…ã†ã›ã„ã€ã€‚ç›¸è«‡è€…ã®ä¸å®‰ã‚’å’Œã‚‰ã’ã€å…·ä½“çš„è¡Œå‹•ã‚’æç¤ºã™ã‚‹ã€‚" },
      ...history.slice(-6).map(m => ({ role: m.role, content: m.content })),
      { role: "user", content: prompt },
    ];
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: { "Content-Type": "application/json", Authorization: `Bearer ${apiKey}` },
      body: JSON.stringify({ model, messages, temperature: 0.8, top_p: 0.9, max_tokens: 700 })
    });
    if (!res.ok) {
      const t = await res.text();
      throw new Error(`OpenAI ${res.status} ${t}`);
    }
    const data = await res.json();
    const out = data.choices?.[0]?.message?.content?.trim();
    console.log("LLM ok");
    return out || null;
  } catch (e) {
    console.error("LLM error:", e.message);
    return null;
  }
}

function fallbackReply() {
  return `ã€çµè«–ã€‘æµã‚Œã¯è½ã¡ç€ã„ã¦ä¸Šå‘ãã€‚ç„¦ã‚‰ãšæ•´ãˆã‚‹ã»ã©æˆæœã«çµã³ã¤ãã¾ã™ã€‚
ã€ç†ç”±ã€‘è¶³å…ƒã‚’å›ºã‚ã‚‹ã»ã©é¸æŠã®è³ªãŒä¸ŠãŒã‚‹é‹æ°—ã€‚
ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘ä»Šæ—¥ã²ã¨ã¤ã ã‘ã€Œé€£çµ¡ï¼æ•´ç†ï¼ãƒ¡ãƒ¢åŒ–ã€ã‚’å®Œäº†ã€‚
ã€æ³¨æ„ç‚¹ã€‘å¤œã®è¡å‹•æ±ºæ–­ã¯å›é¿ã€‚åˆ¤æ–­ã¯ç¿Œæœã«ã€‚
ã€ã²ã¨ã“ã¨åŠ±ã¾ã—ã€‘ä¸å¯§ãªä¸€æ­©ãŒæœªæ¥ã®è¿‘é“ã§ã™ã€‚`;
}

const port = process.env.PORT || 3000;
app.listen(port, () => console.log(`Server running on ${port}`));

// è¿½åŠ ï¼šLLMãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ†ã‚¹ãƒˆå¾Œã«æ¶ˆã—ã¦OKï¼‰
app.get("/ping-llm", async (_, res) => {
  try {
    const msg = await generateWithOpenAI("ãƒ†ã‚¹ãƒˆé‘‘å®šã‚’1æ–‡ã§ã€‚", []);
    if (msg) return res.status(200).send("LLM ok: " + msg.slice(0, 60));
    return res.status(500).send("LLM ng (fallback)");
  } catch (e) {
    return res.status(500).send("LLM error: " + (e.message || e));
  }
});



